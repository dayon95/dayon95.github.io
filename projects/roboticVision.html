<!DOCTYPE html>
<html lang="en">
<script src="http://www.w3schools.com/lib/w3data.js"></script>
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Dayeon's Blog</title>

  <!-- Bootstrap core CSS -->
  <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="../vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

  <!-- Custom styles for this template -->
  <link href="../css/clean-blog.min.css" rel="stylesheet">

</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand" href="../index.html">Dayeon Kim</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fas fa-bars"></i>
        </button>

        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="../index.html">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="../assets/Dayeon_Kim_CV.pdf">Curriculum Vitae</a>
            </li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Projects</a>
              <div class="dropdown-menu">
                <a class="dropdown-item" href="ICRA2019.html">ICRA & RA-L 2019</a>
                <a class="dropdown-item" href="IROS2018.html">IROS & RA-L 2018</a>
                <a class="dropdown-item" href="ICCAS2017.html">ICCAS 2017</a>

                <div class="dropdown-divider"></div>
                <a class="dropdown-item" href="roboticVision.html">Robotic Vision</a>
                <a class="dropdown-item" href="tunetunee.html">Guitar Tuner</a>
              </div>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="../blog.html">Blog</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="../contact.html">Contact</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

  <!-- Page Header -->
  <header class="masthead" style="background-image: url('../img/RoboticVision.png'); height:560px">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-md-10 mx-auto">
          <div class="post-heading" style="top:0">
            <h2 class="display-4" style="font-size:35px"> 3D object pose recognition framework for robot task based on RGB image</h2>
            <br>
            <p class="font-italic">in the 14th Korea Robotics Society Annual Conference (KRoC 2019)</p>
            <br>
          </div>
        </div>
      </div>
    </div>
  </header>

  <!-- Post Content -->
  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <h2 class="section-heading">Introduction </h2>
          <div class="embed-responsive embed-responsive-16by9">
              <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/o4gab-kQA8c" allowfullscreen></iframe>
          </div>
          <p> To bring collaborative robots into our everyday lives, the development of low-cost vision system is essential.
            In this work, we propose a vision framework that recognizes 6D pose of objects, <span class="font-italic">i.e., position and orientation, </span>
          from RGB images. The system is consisted of three main components: ROI Extraction, Keypoint Regression, and 6D Pose Estimation. </p>
          <h2 class="section-heading">Methodology</h2>
          <h4 class="subheading">A. RGB-based Object Recognition</h4>
          <p> As shown in the figure below, we identified the locations of objects, regressed some keypoints, and applied PnP algorithm to find out 6D position of objects.
          To extract the region of interests, we used Mask R-CNN [1] to segment objects from RGB images. From the segmentation results, we estimated 6D pose of the target based on keypoints [2].
          Here, the target can be selected by the user using the graphical user interface (GUI) of the system.
          First, we masked the target object to regress eight keypoints using Stacked Hourglass Network (SHN) [3]. Then, we computed 6D pose of the target by applying PnP algorithm to those keypoints.
          With the estimated 6D pose of the target object, we overlay its 3D model for qualitative evaluation of the algorithm.
          </p>
          <img class="img-fluid" src="img/ObjectRecog.png" alt="">
          <span class="caption text-muted">An overview of 3D object pose recognition framework based on RGB image.</span>
          <h4 class="subheading">B. Automatic Data Acquisition System</h4>
          <p>For training of Mask R-CNN metioned in Section A, we developed our own data acquisition system to automatically collect large amount of data.
          We used a 6-DOF manipulator, <span class="font-italic">i.e., IndyRP from Neuromeka, </span> and attached a stereo camera on the end-effector for the data acquisition system.
          We predefined some positions to be uniformly distributed over the hemi-sphere around the object, and changed the light settings for the robust vision algorithm.
          With the known position of the object and the camera, we labeled the data using 3D model data and the pinhole camera model. As a result, we collected 22,176 images to train Mask R-CNN.
          </p>
          <h2 class="section-heading">Results</h2>
          <div class="text-center">
            <img class="img-fluid" src="img/result-table.PNG" alt="">
          </div>
          <p class="caption text-muted">The accuracy of 6D pose estimation</p>
          <p> The accuracy of our vision system is shown in the table above. Within the error margin of 5cm 5 degrees, we achieved over 60% accuracy in three objects.
            For pick-and-place tasks, we applied the error margin of 3cm 10 degrees and the system has shown over 90% accuarcy in three objects.
            Within this margin, the robot is capable of picking up the object and placing it on the marker successfully, as shown in the figure below.
            The reason why hand cream has shown considerably low accuracy is that it is symmetric, and we would need to find the solution to deal with objects that are symmetric or have little features.
          </p>
          <div class="text-center">
            <img class="img-fluid" src="img/PcpTask.png" alt="">
          </div>
          <span class="caption text-muted">IndyRP performing the pick-and-place tasks. It detects 6D pose of the target, picks it up using the end-effector, and places it on the marker.</span>


        <h2 class="section-heading">References</h2>
        <p>[1]  HE, Kaiming, et al. Mask r-cnn. In: Computer Vision (ICCV), 2017 IEEE International Conference on. IEEE, 2017. p. 2980-2988. </p>
        <p>[2]  PAVLAKOS, Georgios, et al. 6-dof object pose from semantic keypoints. In: Robotics and Automation (ICRA), 2017 IEEE International Conference on. IEEE, 2017. p. 2011-2018. </p>
        <p>[3]  NEWELL, Alejandro; YANG, Kaiyu; DENG, Jia. Stacked hourglass networks for human pose estimation. In: European Conference on Computer Vision. Springer, Cham, 2016. p. 483-499. </p>

        </div>
      </div>
    </div>
  </article>

  <hr>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://www.youtube.com/channel/UC0AIJwMgMpsw-sxHk8tiX7Q">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-youtube fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://www.linkedin.com/in/dayeon-kim-0907/">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://github.com/dayon95">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://www.instagram.com/to_da.y/">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-instagram fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">Copyright &copy; Dayeon Kim</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="../vendor/jquery/jquery.min.js"></script>
  <script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="../js/clean-blog.min.js"></script>
</body>

</html>
